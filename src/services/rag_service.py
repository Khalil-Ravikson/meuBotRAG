import os
import nest_asyncio
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.runnables.history import RunnableWithMessageHistory





# Importa√ß√£o correta da Community
from langchain_community.chat_message_histories import RedisChatMessageHistory

from langchain_core.tools import create_retriever_tool

# Ingest√£o Avan√ßada
from llama_parse import LlamaParse

# --- imports novos no topo do arquivo ---
import re
from langchain_text_splitters import (
    MarkdownHeaderTextSplitter,
    RecursiveCharacterTextSplitter
)
from langchain_core.documents import Document

# Outros
from src.config import settings
from src.services.db_service import get_vector_store
from src.tools import abrir_chamado_glpi, consultar_fila
from groq import Groq 

# Aplica nest_asyncio
nest_asyncio.apply()

class RagService:
    def __init__(self):
        self.agent_with_history = None
        self.vectorstore = get_vector_store()

    # --- 1. INGEST√ÉO INTELIGENTE (LlamaParse) ---
    def ingerir_pdf(self):
        try:
            # Checa se o banco j√° tem algo
            if len(self.vectorstore.similarity_search("calend√°rio", k=1)) > 0:
                print("üíæ Banco j√° populado. Pulando ingest√£o.")
                return
        except Exception:
            pass

        if not os.path.exists(settings.PDF_PATH):
            print(f"‚ö†Ô∏è PDF n√£o encontrado: {settings.PDF_PATH}")
            return

        print("üïµÔ∏è LlamaParse: Convertendo PDF com parsing inteligente...")

        # üî• SYSTEM PROMPT (igual ao do Colab)
        system_prompt = """
        Este √© um calend√°rio acad√™mico.
        IMPORTANTE:
        1. IGNORE grades visuais mensais que contenham apenas n√∫meros de dias (1, 2, 3...).
        2. Extraia APENAS texto relacionado a eventos, feriados, prazos, in√≠cio e fim de per√≠odos.
        3. Converta tabelas relevantes (atividades, p√∫blico-alvo) em Markdown limpo.
        4. Ignore cabe√ßalhos e rodap√©s institucionais repetitivos.
        """

        try:
            parser = LlamaParse(
                api_key=settings.LLAMA_CLOUD_API_KEY,
                result_type="markdown",
                language="pt",
                system_prompt=system_prompt,
                verbose=True
            )

            llama_docs = parser.load_data(settings.PDF_PATH)

            if not llama_docs:
                print("‚ùå LlamaParse n√£o retornou conte√∫do.")
                return

            # --- FUN√á√ÉO DE LIMPEZA ---
            def clean_text(text: str) -> str:
                if not text:
                    return ""

                # Remove pseudo-tabelas s√≥ com n√∫meros
                text = re.sub(r'^\|[\s\d\|-]+\|$', '', text, flags=re.MULTILINE)

                # Remove lixo institucional
                patterns = [
                    r"UNIVERSIDADE ESTADUAL DO MARANH√ÉO",
                    r"Pr√≥-Reitoria de Gradua√ß√£o",
                    r"Cidade Universit√°ria Paulo VI",
                    r"www\.uema\.br",
                ]
                for p in patterns:
                    text = re.sub(p, "", text, flags=re.IGNORECASE)

                # Normaliza quebras de linha
                text = re.sub(r"\n{3,}", "\n\n", text)
                return text.strip()

            # --- SPLITTER POR CABE√áALHOS ---
            header_splitter = MarkdownHeaderTextSplitter(
                headers_to_split_on=[
                    ("#", "contexto_macro"),
                    ("##", "secao_referencia"),
                    ("###", "topico_especifico"),
                ]
            )

            # --- SPLITTER POR TAMANHO ---
            size_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=100,
                separators=["\n\n", "\n", "###", "##"]
            )

            all_chunks: list[Document] = []

            print("üì¶ Processando e limpando chunks...")

            for doc in llama_docs:
                cleaned_text = clean_text(doc.text)

                if not cleaned_text:
                    continue

                # Split sem√¢ntico
                header_docs = header_splitter.split_text(cleaned_text)

                # Injeta metadados
                for hdoc in header_docs:
                    hdoc.metadata.update(doc.metadata)
                    hdoc.metadata["source"] = "calendario_2026"

                # Split final por tamanho
                final_chunks = size_splitter.split_documents(header_docs)
                all_chunks.extend(final_chunks)

            if not all_chunks:
                print("‚ö†Ô∏è Nenhum chunk √∫til gerado.")
                return

            self.vectorstore.add_documents(all_chunks)
            print(f"‚úÖ {len(all_chunks)} chunks limpos salvos no Postgres!")

        except Exception as e:
            print(f"‚ùå Erro durante ingest√£o avan√ßada: {e}")


    # --- 2. TRANSCRI√á√ÉO DE √ÅUDIO ---
    def transcrever_audio(self, caminho_arquivo):
        print(f"üéß Transcrevendo: {caminho_arquivo}")
        try:
            client = Groq(api_key=settings.GROQ_API_KEY)
            with open(caminho_arquivo, "rb") as file:
                return client.audio.transcriptions.create(
                    file=(caminho_arquivo, file.read()),
                    model="whisper-large-v3",
                    response_format="text"
                )
        except Exception as e:
            print(f"‚ùå Erro ao transcrever √°udio: {e}")
            return "Erro ao processar √°udio."

    # --- 3. INICIALIZA√á√ÉO DO AGENTE ---
    def get_session_history(self, session_id: str):
        return RedisChatMessageHistory(session_id, url=settings.REDIS_URL, ttl=3600)

    def inicializar(self):
        print("üß† Inicializando Agente de IA...")

        # --- Retriever ---
        retriever = self.vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={        
                            "k": 5,
                            "fetch_k": 20,
                            "lambda_mult": 0.5
                            })
        tool_pdf = create_retriever_tool(
            retriever,
            "buscar_no_calendario",
            "Use para buscar datas, feriados, prazos e regras no calend√°rio acad√™mico oficial."
        )

        tools = [tool_pdf, abrir_chamado_glpi, consultar_fila]

        # --- LLM ---
        llm = ChatGroq(
            api_key=settings.GROQ_API_KEY,
            model="llama-3.3-70b-versatile",
            temperature=0.3
        )

        # --- Agente ---
        agent_executor = self._criar_agente(llm, tools)

        # --- Mem√≥ria Redis ---
        self.agent_with_history = RunnableWithMessageHistory(
            agent_executor,
            self.get_session_history,
            input_messages_key="input",
            history_messages_key="history"
        )

        print("‚úÖ Agente Pronto!")


    def responder(self, texto: str, user_id: str):
        if self.agent_with_history is None:
            return "‚ö†Ô∏è O sistema est√° iniciando, por favor tente novamente em alguns segundos."
            
        config = {"configurable": {"session_id": user_id}}
        
        try:
            resultado = self.agent_with_history.invoke(
                {"input": texto},
                config=config
            )
            return resultado["output"]
        except Exception as e:
            print(f"‚ùå Erro ao gerar resposta: {e}")
            return "Desculpe, tive um erro interno ao processar seu pedido."
        
        
    
    
    def _criar_agente(self, llm, tools):
        # Prompt do Sistema (Blindado e S√©rio)
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© o Assistente Virtual Institucional da UEMA (Universidade Estadual do Maranh√£o).
                Sua postura √© ESTRITAMENTE profissional, objetiva e impessoal.

                üö® REGRAS DE OURO (ESCOPO):
                1. O seu √öNICO objetivo √© auxiliar com: Calend√°rio Acad√™mico, Suporte T√©cnico (GLPI) e Processos da UEMA.
                2. Se o usu√°rio falar sobre QUALQUER assunto externo (pol√≠tica, futebol, promo√ß√µes, receitas, piadas, clima, fofoca), voc√™ DEVE responder:
                "Desculpe, meu escopo de atua√ß√£o limita-se exclusivamente a assuntos acad√™micos e t√©cnicos da UEMA."
                3. N√ÉO emita opini√µes pessoais e N√ÉO tente ser engra√ßado.

                üõ†Ô∏è INSTRU√á√ïES DE FERRAMENTAS:
                - Perguntas sobre Datas, Prazos ou Feriados: Voc√™ √â OBRIGADO a usar a ferramenta 'buscar_no_calendario'. N√£o invente datas.
                - Relato de Problemas (PC quebrou, sem internet): Use 'abrir_chamado_glpi'.
                - Consultas de Status: Use 'consultar_fila'.

                üëã SAUDA√á√ïES:
                - Se o usu√°rio disser "Oi", "Bom dia", etc: Responda apenas:
                "Ol√°. Sou o assistente da UEMA. Em que posso ajudar referente √† universidade?"

                Seja breve. N√£o enrole."""),
                    MessagesPlaceholder(variable_name="history"),
                    ("human", "{input}"),
                    ("placeholder", "{agent_scratchpad}"),
                ])

        agent = create_tool_calling_agent(llm, tools, prompt)

        return AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True
        )

    